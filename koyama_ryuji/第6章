import pandas as pd
import numpy as np

data_url = "http://lib.stat.cmu.edu/datasets/boston"
raw_df = pd.read_csv(data_url, sep="\s+", skiprows=22, header=None)
data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
target = raw_df.values[1::2, 2]

df = pd.DataFrame(data)

col_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']
for i, col_name in enumerate(col_names):
    df = df.rename(columns={i: col_name})



df_target = pd.DataFrame(target)
df_target = df_target.rename(columns={0: 'MEDV'})

X = df
y = df_target

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor(max_depth=3, random_state=0).fit(X_train, y_train)

from sklearn import tree
import matplotlib.pyplot as plt
%matplotlib inline

plt.figure(figsize=(20, 8))
tree.plot_tree(tree_reg, fontsize=20)

y_train_pred = tree_reg.predict(X_train)
y_test_pred = tree_reg.predict(X_test)

import numpy as np

y_train_pred = np.expand_dims(y_train_pred, 1)
y_test_pred = np.expand_dims(y_test_pred, 1)

plt.scatter(y_train_pred, y_train, label='train')
plt.scatter(y_test_pred, y_test, label='test')
plt.xlabel('Pred')
plt.ylabel('True')
plt.legend()
plt.show()

def residual_plot(y_train_pred, y_train, y_test_pred, y_test):
    plt.scatter(y_train_pred, y_train_pred - y_train, label='train')
    plt.scatter(y_test_pred, y_test_pred - y_test, label='test')
    plt.plot([0, 50], [0, 0], color='red')
    plt.xlabel('Pred')
    plt.ylabel('True')
    plt.legend()
    plt.show()

residual_plot(y_train_pred, y_train, y_test_pred, y_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

def get_eval_score(y_true, y_pred):
    
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2score = r2_score(y_true, y_pred)

    print(f'MAE = {mae}')
    print(f'MSE = {mse}')
    print(f'RMSE = {rmse}')
    print(f'R"SCORE = {r2score}')
    
print('訓練データスコア')
get_eval_score(y_train, y_train_pred)
print('テストデータスコア')
get_eval_score(y_test, y_test_pred)

tree_reg_depth_5 = DecisionTreeRegressor(max_depth=5, random_state=0).fit(X_train, y_train)

y_train_pred = tree_reg_depth_5.predict(X_train)
y_test_pred = tree_reg_depth_5.predict(X_test)

y_train_pred = np.expand_dims(y_train_pred, 1)
y_test_pred = np.expand_dims(y_test_pred, 1)

residual_plot(y_train_pred, y_train, y_test_pred, y_test)

print('train')
get_eval_score(y_train, y_train_pred)
print('test')
get_eval_score(y_test, y_test_pred)

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=0).fit(X_train, y_train)

y_train_pred = rf.predict(X_train)
y_test_pred = rf.predict(X_test)

y_train_pred = np.expand_dims(y_train_pred, 1)
y_test_pred = np.expand_dims(y_test_pred, 1)

residual_plot(y_train_pred, y_train, y_test_pred, y_test)

print('train')
get_eval_score(y_train, y_train_pred)
print('test')
get_eval_score(y_test, y_test_pred)

rf_change_param = RandomForestRegressor(n_estimators=3, max_depth=20, random_state=0).fit(X_train, y_train)

y_train_pred = rf_change_param.predict(X_train)
y_test_pred = rf_change_param.predict(X_test)

y_train_pred = np.expand_dims(y_train_pred, 1)
y_test_pred = np.expand_dims(y_test_pred, 1)

residual_plot(y_train_pred, y_train, y_test_pred, y_test)

print('train')
get_eval_score(y_train, y_train_pred)
print('test')
get_eval_score(y_test, y_test_pred)

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

rf_cv = RandomForestRegressor(n_estimators=3, max_depth=5, random_state=0)
k_fold = KFold(n_splits=5, shuffle=True, random_state=0)
rf_scores = cross_val_score(estimator=rf_cv, X=X, y=y, cv=k_fold, scoring=('r2'))

print(f'各分割のスコア: {rf_scores}')
print(f'平均スコア: {np.mean(rf_scores)}')

import xgboost as xgb

xgb_reg = xgb.XGBRegressor(random_state=0)
k_fold = KFold(n_splits=5, shuffle=True, random_state=0)
xgb_scores = cross_val_score(xgb_reg, X, y, cv=k_fold, scoring='r2')

print(f'各分割のスコア: {xgb_scores}')
print(f'平均スコア: {np.mean(xgb_scores)}')

xgb_reg_grid = xgb.XGBRFRegressor()

from sklearn.model_selection import GridSearchCV

params = {'booster': ['gbtree'],
         'n_estimators': [10, 30, 50, 100],
         'max_depth': [2, 3, 4, 5, 6],
         'learning_rate': [0.1, 0.25, 0.5, 0.75, 1.0],
         'random_state': [0]
         }

k_fold = KFold(n_splits=5, shuffle=True, random_state=0)
grid = GridSearchCV(estimator=xgb_reg_grid, param_grid=params, cv=k_fold, scoring='r2')

grid.fit(X_train, y_train)

print(grid.best_params_)
print(grid.best_score_)

y_test_pred = grid.predict(X_test)
y_test_pred = np.expand_dims(y_test_pred, 1)

print('テストデータスコア')
get_eval_score(y_test, y_test_pred)

xgb_reg_random = xgb.XGBRFRegressor()

from sklearn.model_selection import RandomizedSearchCV

params = {'booster': ['gbtree'],
         'n_estimators': [10, 30, 50, 100],
         'max_depth': [2, 3, 4, 5, 6],
         'learning_rate': [0.1, 0.25, 0.5, 0.75, 1.0],
         'random_state': [0]
         }

k_fold = KFold(n_splits=5, shuffle=True, random_state=0)
random = RandomizedSearchCV(estimator=xgb_reg_random, param_distributions=params, cv=k_fold, scoring='r2', n_iter=30, random_state=0)

random.fit(X_train, y_train)
print(random.best_params_)
print(random.best_score_)

y_test_pred = random.predict(X_test)
y_test_pred = np.expand_dims(y_test_pred, 1)

print('データスコア')
get_eval_score(y_test, y_test_pred)

